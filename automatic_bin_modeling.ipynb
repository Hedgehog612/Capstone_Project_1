{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import io\n",
    "import requests\n",
    "import matplotlib.collections as col\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.graphics.regressionplots import *\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import rcParams\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Going to make an automated tester to find the best binning for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPolls = pd.read_csv('all_polls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorPolls = allPolls[['samplesize', 'error', 'bias', 'pollster', 'state', 'type_simple', 'partisan_race']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing some outliers. errorPolls has all the most relevant columns from allPolls with the\n",
    "#outliers trimmed out.\n",
    "errorPolls = errorPolls[errorPolls['error'] < 90]\n",
    "errorPolls.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollerror = allPolls.groupby('pollster').mean()\n",
    "pollerror = pollerror[['error']]\n",
    "pollstd = allPolls.groupby('pollster').std()\n",
    "pollstd = pollstd[['error']]\n",
    "pollerror.rename(columns = {'error':'pollster_error'}, inplace = True)\n",
    "pollstd.rename(columns = {'error':'pollster_std'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make and return the binned data we'll be using\n",
    "def makeBins(binSize, pollerror, pollstd):\n",
    "    binData = pd.DataFrame()\n",
    "    binData['samplesize'] = range(0, 4000, binSize)\n",
    "    binData['error'] = 0\n",
    "    binData['pos_bias'] = 0\n",
    "    binData['neg_bias'] = 0\n",
    "    binData['pollster'] = ''\n",
    "    binData['type_simple'] = ''\n",
    "    binData['state'] = ''\n",
    "    binData['partisan_race'] = 0\n",
    "    binData = errorPopulate(binSize, binData, errorPolls)\n",
    "    binData = binData.merge(pollerror, how = 'left', left_on = 'pollster', right_on = 'pollster')\n",
    "    binData = binData.merge(pollstd, how = 'left', left_on = 'pollster', right_on = 'pollster')\n",
    "    binData = binData[binData['error'] != 0]\n",
    "    binData['log_error'] = np.log(binData['error'])\n",
    "    binData.dropna(inplace = True)\n",
    "    return binData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorPopulate(binSize, binData, errorPolls):\n",
    "    for entry in range(len(errorPolls)):\n",
    "        currentError = errorPolls['error'][entry]\n",
    "        #Round sample size to the nearest binSize\n",
    "        sampleSize = (errorPolls['samplesize'][entry] + \n",
    "                      (binSize - errorPolls['samplesize'][entry]) % binSize)\n",
    "        #Make sure we don't go over\n",
    "        if sampleSize in binData['samplesize'].values:\n",
    "            if binData['error'][sampleSize/binSize] < currentError:\n",
    "                binData['error'][sampleSize/binSize] = currentError\n",
    "                binData['pollster'][sampleSize/binSize] = errorPolls['pollster'][entry]\n",
    "                binData['type_simple'][sampleSize/binSize] = errorPolls['type_simple'][entry]\n",
    "                binData['state'][sampleSize/binSize] = errorPolls['state'][entry]\n",
    "                binData['partisan_race'][sampleSize/binSize] = errorPolls['partisan_race'][entry]\n",
    "    return binData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test binnings from 1-100, return R-squared values, F values as tuples\n",
    "def calculate_best_binning(pollerror, pollstd):\n",
    "    binScores = []\n",
    "    for binSize in range(100):\n",
    "        #We don't want bins of 0\n",
    "        binData = makeBins(binSize+1, pollerror, pollstd)\n",
    "        x = binData[['samplesize', 'pollster_std']]\n",
    "        y = binData['log_error']\n",
    "        testModel = sm.OLS(y, x).fit()\n",
    "        binScores.append((testModel.rsquared_adj, testModel.fvalue))\n",
    "    return binScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8165235541408629 2993.820618409555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    " binData = makeBins(1, pollerror, pollstd)\n",
    "x = binData[['samplesize', 'pollster_std']]\n",
    "y = binData['log_error']\n",
    "testModel = sm.OLS(y, x).fit()\n",
    "print(testModel.rsquared_adj, testModel.fvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "binScores = calculate_best_binning(pollerror, pollstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsquared_adj = []\n",
    "f_score = []\n",
    "for x in binScores:\n",
    "    rsquared_adj.append(x[0])\n",
    "    f_score.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y= f_score, x = range(100), s = 5)\n",
    "plt.xlabel('Bin size')\n",
    "plt.ylabel('F-statistic')\n",
    "plt.title('F-statistic at varying bin sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y= rsquared_adj, x = range(100), s = 5, c = 'red')\n",
    "plt.xlabel('Bin size')\n",
    "plt.ylabel('Adjusted R-squared')\n",
    "plt.title('R-squared at varying bin sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for x in range(len(rsquared_adj)):\n",
    "    test.append(rsquared_adj[x] * f_score[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y = test, x = range(100), s = 5)\n",
    "plt.xlabel('Bin size')\n",
    "plt.ylabel('F-statistic * R-squared')\n",
    "plt.title('Multiplying R-squared by F-statistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorPolls = errorPolls.merge(pollstd, how = 'left', left_on = 'pollster', right_on = 'pollster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errorPolls['log_error'] = np.log(errorPolls['error'])\n",
    "errorPolls.dropna(inplace = True)\n",
    "#Remove -inf in the logs\n",
    "errorPolls = errorPolls[errorPolls['log_error'] > -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:              log_error   R-squared (uncentered):                   0.516\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.516\n",
      "Method:                 Least Squares   F-statistic:                              5349.\n",
      "Date:                Sun, 01 Mar 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        16:24:51   Log-Likelihood:                         -15959.\n",
      "No. Observations:               10038   AIC:                                  3.192e+04\n",
      "Df Residuals:                   10036   BIC:                                  3.194e+04\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "samplesize    4.907e-06   5.87e-06      0.836      0.403    -6.6e-06    1.64e-05\n",
      "pollster_std     0.2595      0.003     95.799      0.000       0.254       0.265\n",
      "==============================================================================\n",
      "Omnibus:                     9298.933   Durbin-Watson:                   1.163\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2372389.614\n",
      "Skew:                          -3.783   Prob(JB):                         0.00\n",
      "Kurtosis:                      77.933   Cond. No.                         497.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "x = errorPolls[['samplesize', 'pollster_std']]\n",
    "y = errorPolls['log_error']\n",
    "testModel = sm.OLS(y, x).fit()\n",
    "print(testModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "x = errorPolls[['samplesize', 'pollster_std']]\n",
    "y = errorPolls['log_error']\n",
    "print(type(y[83]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in errorPolls['samplesize']:\n",
    "    if type(x) != float:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10060 10060\n"
     ]
    }
   ],
   "source": [
    "print(len(errorPolls['samplesize']), len(errorPolls['pollster_std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10060\n"
     ]
    }
   ],
   "source": [
    "print(len(errorPolls['log_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(np.log(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>log_error</td>    <th>  R-squared (uncentered):</th>      <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 01 Mar 2020</td> <th>  Prob (F-statistic):</th>           <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:11:27</td>     <th>  Log-Likelihood:    </th>          <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th>          <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th>          <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>samplesize</th>   <td>      -inf</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pollster_std</th> <td>       inf</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>   nan</td> <th>  Prob(JB):          </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>   nan</td> <th>  Cond. No.          </th> <td>    59.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:              log_error   R-squared (uncentered):                     nan\n",
       "Model:                            OLS   Adj. R-squared (uncentered):                nan\n",
       "Method:                 Least Squares   F-statistic:                                nan\n",
       "Date:                Sun, 01 Mar 2020   Prob (F-statistic):                         nan\n",
       "Time:                        16:11:27   Log-Likelihood:                             nan\n",
       "No. Observations:                 100   AIC:                                        nan\n",
       "Df Residuals:                      98   BIC:                                        nan\n",
       "Df Model:                           2                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "samplesize         -inf        nan        nan        nan         nan         nan\n",
       "pollster_std        inf        nan        nan        nan         nan         nan\n",
       "==============================================================================\n",
       "Omnibus:                          nan   Durbin-Watson:                     nan\n",
       "Prob(Omnibus):                    nan   Jarque-Bera (JB):                  nan\n",
       "Skew:                             nan   Prob(JB):                          nan\n",
       "Kurtosis:                         nan   Cond. No.                         59.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5c79545e12a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'f_score' is not defined"
     ]
    }
   ],
   "source": [
    "print(f_score[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
